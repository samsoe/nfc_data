{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some quick resources for wx data while I am thinking of it....\n",
    "mesowest is a great one. it has all of the government weather stations: http://mesowest.utah.edu/\n",
    "wunderground has the mpg wx stations: mpgweather.com\n",
    "More to come!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step for wx data: is there a way to automatically download this while we are recording for NFCs. So all the wx stations of interest from start date x to end date x are archived either in real time or not. The archived files are in whatever format for us to import into analysis and analysis software. Think ready to go with little manipulation required by us.\n",
    "Typical weather variables we are interested in:\n",
    "temp, wind speed and direction, ceiling height (only available at major airports, I believe), cloud cover, barometric pressure, etc. There maybe more I am forgetting....\n",
    "As far as radar, I want the Nexrad wx radar from Montana doppler radar sites. I have to track down the websites for this yet. But here is an example of someone who makes maps from available data. http://www.pauljhurtado.com/US_Composite_Radar/\n",
    "Ultimately, what I want is a csv or txt with the raw radar values from these sorts of images. I want the pixel values at our monitoring sites and then buffered at 300 and 600m from point center and and get focal statistics for each. Does that make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2.7\n",
    "import os, requests, datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  for station in station_list:\n",
    "    # Generate URL\n",
    "    url = station_url(station)\n",
    "    \n",
    "    # Format BeautifulSoup\n",
    "    soup = read_url(url)\n",
    "    \n",
    "    # Parse soup\n",
    "    weather_values = extract_wx_values(soup, station)\n",
    "    \n",
    "    # Combine col_names, wx_values into DataFrame\n",
    "    df = pd.DataFrame(data=[weather_values], columns=col_names)\n",
    "    \n",
    "    # Write to .csv\n",
    "    write_result(df)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_list = ['KMTFLORE2', 'KMTFLORE7', 'KMTSTEVE13', \n",
    "                'KMTSTEVE12', 'KMTFLORE17', 'KMTFLORE18', 'KMTFLORE11', \n",
    "                'KMTFLORE12', 'KMTFLORE14', 'KMTVICTO9', 'KMTCORVA12', \n",
    "                'KMTCORVA11', 'KMTCORVA15', 'KMTCORVA10', 'KMTLOLO7', \n",
    "                'KMTLOLO4', 'KMTLOLO3', 'KMTLOLO2', 'KMTHAMIL13', \n",
    "                'KMTHAMIL7', 'KMTSTEVE8', 'KMTCORVA9']\n",
    "\n",
    "airport_list = ['KMSO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column names\n",
    "col_names = ['date_time', 'station', 'temp', 'feels_like', 'wind_speed', \n",
    "           'wind_direction', 'gusts', 'dew_point', 'humidity', \n",
    "           'precip_rate', 'accum_precip', 'pressure', 'solar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define url\n",
    "def station_url(station):\n",
    "    s_url = 'https://www.wunderground.com/personal-weather-station/dashboard?ID=' + station\n",
    "    return(s_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_url(url):\n",
    "    # Make the request and check object type\n",
    "    r = requests.get(url)\n",
    "\n",
    "    # Extract HTML from Response object and print\n",
    "    html = r.text\n",
    "    \n",
    "    # Create a BeautifulSoup object from the HTML\n",
    "    soup = BeautifulSoup(html, \"html5lib\")\n",
    "    return(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wx_values(soup, station):\n",
    "    wx_values = []\n",
    "    \n",
    "    # parse soup for wx_values\n",
    "    wx_element = soup.findAll('span', class_='wx-value')\n",
    "    for value in wx_element:\n",
    "        v = value.contents[0].strip()\n",
    "        wx_values.append(v)\n",
    "    \n",
    "    # add date_time and station\n",
    "    now = datetime.datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d %H%M\")\n",
    "    wx_values = [date_time] + [station] + wx_values\n",
    "    \n",
    "    # fix for missing solar wx_value\n",
    "    while len(wx_values) < 13:\n",
    "        wx_values.append('None')\n",
    "\n",
    "    return(wx_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_result(df):\n",
    "    dirname = './'\n",
    "    filename = now.strftime(\"%Y%m%d_%H%M\")+ '.csv'\n",
    "\n",
    "    if os.path.exists(dirname+filename):\n",
    "        with open(dirname + filename, 'a') as f:\n",
    "            df.to_csv(f, header=False, index=False)\n",
    "    else:        \n",
    "        df.to_csv(dirname + filename, index=False)\n",
    "        \n",
    "        #print(dirname+filename)\n",
    "        #print(df[['station', 'temp', 'date_time', 'solar']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
